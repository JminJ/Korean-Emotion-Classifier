{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "korean_semactic_classification_trainer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpWHNeifIQMK"
      },
      "source": [
        "## Install & Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvYwZZS_I5xD",
        "outputId": "cfcafc80-c4b9-40bc-f1e9-a8b1f6765efb"
      },
      "source": [
        "!pip install import_ipynb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import_ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=2ab021b9415b99c6d24c873dbb41746e08d782d81cd955748088f4230845960d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJhE-RCoJ6lC",
        "outputId": "9f97f69c-4377-4410-fe2f-72cca23744f8"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/4d/49a158b7e7ce3e31d2b921eea274c945e48eea07eb9df3da987b64ee87b6/pytorch_ignite-0.4.3-py3-none-any.whl (193kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 18.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 14.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 51kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 61kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 71kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 81kB 10.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 92kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 133kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 143kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 153kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 163kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 174kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 184kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (0.16.0)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28wSZFVbKsvY",
        "outputId": "2a7d22df-970b-40dd-f2b5-beb4e97f14ab"
      },
      "source": [
        "# this code used in colab. \r\n",
        "%cd /content/drive/MyDrive/Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HGxl9isMU-T"
      },
      "source": [
        "from copy import copy\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "from ignite.engine import Engine\r\n",
        "from ignite.engine import Events\r\n",
        "from ignite.metrics import RunningAverage\r\n",
        "from ignite.contrib.handlers.tqdm_logger import ProgressBar\r\n",
        "\r\n",
        "import import_ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIlHmVwdKyM8"
      },
      "source": [
        "import korean_semantic_classification_utils as utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5AVRh4iLjws"
      },
      "source": [
        "## Define our trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj1C3tZ4LdM9"
      },
      "source": [
        "VERBOSE_SILENT = 0\r\n",
        "VERBOSE_EPOCH_WISE = 1\r\n",
        "VERBOSE_BATCH_WISE = 2\r\n",
        "\r\n",
        "class MyEngine(Engine):\r\n",
        "    def __init__(self, func, model, crit, optimizer, config):\r\n",
        "      self.model = model\r\n",
        "      self.crit = crit\r\n",
        "      self.optimizer = optimizer\r\n",
        "      self.config = config\r\n",
        "\r\n",
        "      super().__init__(func)\r\n",
        "\r\n",
        "      self.best_loss = np.inf\r\n",
        "      self.best_model = None\r\n",
        "\r\n",
        "      self.device = next(model.parameters()).device\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def train(engine, mini_batch):\r\n",
        "      engine.model.train()\r\n",
        "      engine.optimizer.zero_grad()\r\n",
        "\r\n",
        "      x, y = mini_batch.text, mini_batch.label\r\n",
        "      x, y = x.to(engine.device), y.to(engine.device)\r\n",
        "\r\n",
        "      x = x[:, :engine.config.max_length]\r\n",
        "\r\n",
        "      # Take feed-forward\r\n",
        "      y_hat = engine.model(x)\r\n",
        "\r\n",
        "      loss = engine.crit(y_hat, y)\r\n",
        "      loss.backward()\r\n",
        "\r\n",
        "      if isinstance(y, torch.longTensor) or isinstance(y, torch.cuda.LongTensor):\r\n",
        "        accuracy = (torch.argmax(y_hat, dim = -1) == y).sum() / float(y.size(0))\r\n",
        "      else:\r\n",
        "        accuracy = 0\r\n",
        "\r\n",
        "      p_norm = float(utils.get_parameter_norm(engine.model.parameters()))\r\n",
        "      g_norm = float(utils.get_grad_norm(engine.model.parameters()))\r\n",
        "\r\n",
        "      engine.optimizer.step()\r\n",
        "\r\n",
        "      return {\r\n",
        "          'loss' : float(loss),\r\n",
        "          'accuracy' : float(accuracy),\r\n",
        "          '|param|' : p_norm,\r\n",
        "          '|g_norm|' : g_norm,\r\n",
        "      }\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def validate(engine, mini_batch):\r\n",
        "      engine.model.eval()\r\n",
        "\r\n",
        "      with torch.no_grad():\r\n",
        "        x, y = mini_batch.text, mini_batch.label\r\n",
        "        x, y = x.to(engine.device), y.to(engine.device)\r\n",
        "\r\n",
        "        x = x[:, :engine.config.max_length]\r\n",
        "\r\n",
        "        y_hat = engine.model(x)\r\n",
        "        \r\n",
        "        loss = engine.crit(y_hat, y)\r\n",
        "\r\n",
        "        if instance(y, torch.LongTensor) or isinstance(y, torch.cuda.LongTensor):\r\n",
        "          accuracy = (torch.argmax(y_hat, dim = -1) == y).sum() / float(y.size(0))\r\n",
        "        else:\r\n",
        "          accuracy = 0\r\n",
        "      \r\n",
        "      return {\r\n",
        "          'loss' : float(loss),\r\n",
        "          'accuracy' : float(accuracy),\r\n",
        "      }\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def attach(train_engine, validation_engine, verbose = VERBOSE_BATCH_WISE):\r\n",
        "      def attach_running_average(engine, metric_name):\r\n",
        "        RunningAverage(output_transform = lambda x : x[metric_name]).attach(\r\n",
        "            engine,\r\n",
        "            metric_name,\r\n",
        "        )\r\n",
        "      \r\n",
        "      training_metric_names = ['loss','accuracy', '|param|', '|g_param']\r\n",
        "\r\n",
        "      for metric_name in training_metric_names:\r\n",
        "        attach_running_average(train_engine, metric_name)\r\n",
        "\r\n",
        "      if verbose >= VERBOSE_BATCH_WISE:\r\n",
        "        pbar = ProgressBar(bar_format = None, ncols = 120)\r\n",
        "        pbar.attach(train_engine, training_metric_names)\r\n",
        "\r\n",
        "      if verbose >= VERBOSE_EPOCH_WISE:\r\n",
        "        @train_engine.on(Events.EPOCH_COMPLETED)\r\n",
        "        def print_train_logs(engine):\r\n",
        "          print('Epoch {} - |param| = {:.2e} loss = {:.4e} accuracy = {:.4f}'.format(\r\n",
        "              engine.state.epoch,\r\n",
        "              engine.state.metrics['|param|'],\r\n",
        "              engine.state.metrics['|g_param|'],\r\n",
        "              engine.state.metrics['loss'],\r\n",
        "              engine.state.metrics['accuracy'],\r\n",
        "          ))\r\n",
        "\r\n",
        "        validation_metric_names = ['loss', 'accuracy']\r\n",
        "\r\n",
        "        for metric_name in validation_metric_names:\r\n",
        "          attch_running_average(validation_engine, metric_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}