{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "korean_semactic_classification_trainer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpWHNeifIQMK"
      },
      "source": [
        "## Install & Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvYwZZS_I5xD",
        "outputId": "cfcafc80-c4b9-40bc-f1e9-a8b1f6765efb"
      },
      "source": [
        "!pip install import_ipynb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import_ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=2ab021b9415b99c6d24c873dbb41746e08d782d81cd955748088f4230845960d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJhE-RCoJ6lC",
        "outputId": "9f97f69c-4377-4410-fe2f-72cca23744f8"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/4d/49a158b7e7ce3e31d2b921eea274c945e48eea07eb9df3da987b64ee87b6/pytorch_ignite-0.4.3-py3-none-any.whl (193kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 18.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 14.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 51kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 61kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 71kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 81kB 10.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 92kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 133kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 143kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 153kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 163kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 174kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 184kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (0.16.0)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28wSZFVbKsvY",
        "outputId": "2a7d22df-970b-40dd-f2b5-beb4e97f14ab"
      },
      "source": [
        "# this code used in colab. \r\n",
        "%cd /content/drive/MyDrive/Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HGxl9isMU-T"
      },
      "source": [
        "from copy import copy\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "from ignite.engine import Engine\r\n",
        "from ignite.engine import Events\r\n",
        "from ignite.metrics import RunningAverage\r\n",
        "from ignite.contrib.handlers.tqdm_logger import ProgressBar\r\n",
        "\r\n",
        "import import_ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIlHmVwdKyM8"
      },
      "source": [
        "import korean_semantic_classification_utils as utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5AVRh4iLjws"
      },
      "source": [
        "## Define our trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj1C3tZ4LdM9"
      },
      "source": [
        "VERBOSE_SILENT = 0\n",
        "VERBOSE_EPOCH_WISE = 1\n",
        "VERBOSE_BATCH_WISE = 2\n",
        "\n",
        "class MyEngine(Engine):\n",
        "    def __init__(self, func, model, crit, optimizer, config):\n",
        "      self.model = model\n",
        "      self.crit = crit\n",
        "      self.optimizer = optimizer\n",
        "      self.config = config\n",
        "\n",
        "      super().__init__(func)\n",
        "\n",
        "      self.best_loss = np.inf\n",
        "      self.best_model = None\n",
        "\n",
        "      self.device = next(model.parameters()).device\n",
        "\n",
        "    @staticmethod\n",
        "    def train(engine, mini_batch):\n",
        "      engine.model.train()\n",
        "      engine.optimizer.zero_grad()\n",
        "\n",
        "      x, y = mini_batch.text, mini_batch.label\n",
        "      x, y = x.to(engine.device), y.to(engine.device)\n",
        "\n",
        "      x = x[:, :engine.config.max_length]\n",
        "\n",
        "      # Take feed-forward\n",
        "      y_hat = engine.model(x)\n",
        "\n",
        "      loss = engine.crit(y_hat, y)\n",
        "      loss.backward()\n",
        "\n",
        "      if isinstance(y, torch.longTensor) or isinstance(y, torch.cuda.LongTensor):\n",
        "        accuracy = (torch.argmax(y_hat, dim = -1) == y).sum() / float(y.size(0))\n",
        "      else:\n",
        "        accuracy = 0\n",
        "\n",
        "      p_norm = float(utils.get_parameter_norm(engine.model.parameters()))\n",
        "      g_norm = float(utils.get_grad_norm(engine.model.parameters()))\n",
        "\n",
        "      engine.optimizer.step()\n",
        "\n",
        "      return {\n",
        "          'loss' : float(loss),\n",
        "          'accuracy' : float(accuracy),\n",
        "          '|param|' : p_norm,\n",
        "          '|g_norm|' : g_norm,\n",
        "      }\n",
        "\n",
        "    @staticmethod\n",
        "    def validate(engine, mini_batch):\n",
        "      engine.model.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        x, y = mini_batch.text, mini_batch.label\n",
        "        x, y = x.to(engine.device), y.to(engine.device)\n",
        "\n",
        "        x = x[:, :engine.config.max_length]\n",
        "\n",
        "        y_hat = engine.model(x)\n",
        "        \n",
        "        loss = engine.crit(y_hat, y)\n",
        "\n",
        "        if instance(y, torch.LongTensor) or isinstance(y, torch.cuda.LongTensor):\n",
        "          accuracy = (torch.argmax(y_hat, dim = -1) == y).sum() / float(y.size(0))\n",
        "        else:\n",
        "          accuracy = 0\n",
        "      \n",
        "      return {\n",
        "          'loss' : float(loss),\n",
        "          'accuracy' : float(accuracy),\n",
        "      }\n",
        "\n",
        "    @staticmethod\n",
        "    def attach(train_engine, validation_engine, verbose = VERBOSE_BATCH_WISE):\n",
        "      def attach_running_average(engine, metric_name):\n",
        "        RunningAverage(output_transform = lambda x : x[metric_name]).attach(\n",
        "            engine,\n",
        "            metric_name,\n",
        "        )\n",
        "      \n",
        "      training_metric_names = ['loss','accuracy', '|param|', '|g_param|']\n",
        "\n",
        "      for metric_name in training_metric_names:\n",
        "        attach_running_average(train_engine, metric_name)\n",
        "\n",
        "      if verbose >= VERBOSE_BATCH_WISE:\n",
        "        pbar = ProgressBar(bar_format = None, ncols = 120)\n",
        "        pbar.attach(train_engine, training_metric_names)\n",
        "\n",
        "      if verbose >= VERBOSE_EPOCH_WISE:\n",
        "        @train_engine.on(Events.EPOCH_COMPLETED)\n",
        "        def print_train_logs(engine):\n",
        "          print('Epoch {} - |param| = {:.2e} loss = {:.4e} accuracy = {:.4f}'.format(\n",
        "              engine.state.epoch,\n",
        "              engine.state.metrics['|param|'],\n",
        "              engine.state.metrics['|g_param|'],\n",
        "              engine.state.metrics['loss'],\n",
        "              engine.state.metrics['accuracy'],\n",
        "          ))\n",
        "      validation_metric_names = ['loss', 'accuracy']\n",
        "\n",
        "      for metric_name in validation_metric_names:\n",
        "        attach_running_average(validation_engine, metric_name)\n",
        "\n",
        "      if verbose >= VERBOSE_EPOCH_WISE:\n",
        "        @valid_engine.on(Events.EPOCH_COMPLETED)\n",
        "        def print_valid_logs(engine):\n",
        "          print('Validation - loss={:.4e} accuracy={:.4f} best_loss={:.4e}'.format(\n",
        "            engine.state.metrics['loss'],\n",
        "            engine.state.metrics['accuracy'],\n",
        "            engine.best_loss,\n",
        "          ))\n",
        "\n",
        "    @staticmethod\n",
        "    def check_best(engine):\n",
        "      loss = float(engine.state.metrics['loss'])\n",
        "      if loss <= engine.best_loss:\n",
        "        engine.best_loss = loss\n",
        "        engine.best_model = deepcopy(engine.model.state_dict())\n",
        "\n",
        "    @staticmethod\n",
        "    def save_model(engine, train_engine, config, **kwargs):\n",
        "      torch.save(\n",
        "          {\n",
        "              'model' : engine.best_model,\n",
        "              'config': config,\n",
        "              **kwargs\n",
        "          }, config.model_fn\n",
        "      )\n",
        "          \n",
        "class Trainer():\n",
        "  def __init__(self, config):\n",
        "    self.config = config\n",
        "\n",
        "  def train(self, model, crit, optimizer, train_loader, valid_loader,):\n",
        "    train_engine = MyEngine(MyEngine.train, model, crit, optimizer, self.config)\n",
        "    validation_engine = MyEngine(MyEngine.validate, model, crit, optimizer, self.config)\n",
        "    MyEngine.attach(\n",
        "        train_engine, validation_engine, verbose = self.config.verbose\n",
        "    )\n",
        "\n",
        "    def run_validation(engine, validation_engine, valid_loader):\n",
        "      validation_engine.run(valid_loader, max_epochs = 1)\n",
        "    \n",
        "    train_engine.add_event_handler(\n",
        "        Events.EPOCH_COMPLETED,\n",
        "        run_validation,\n",
        "        validation_engine, valid_loader,\n",
        "    )\n",
        "\n",
        "    validation_engine.add_event_handler(\n",
        "        Events.EPOCH_COMPLETED,\n",
        "        MyEngine.check_best,\n",
        "    )\n",
        "\n",
        "    train_engine.run(train_loader, max_epochs = self.config.n_epochs,)\n",
        "\n",
        "    model.load_state_dict(validation_engine.best_model)\n",
        "\n",
        "    return model\n",
        "          \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}