{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "korean_sementic_classification_Dataloader.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s6tflT0dz1t"
      },
      "source": [
        "## Install konlpy and Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB0YOst9bh4V",
        "outputId": "3177c77d-fd39-4e18-f34d-918d28f7c186"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/af/93f92b38ec1ff3091cd38982ed19cea2800fefb609b5801c41fc43c0781e/JPype1-1.2.1-cp36-cp36m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 38.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.8MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: JPype1, beautifulsoup4, colorama, tweepy, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nivnbWCabu76"
      },
      "source": [
        "import torch\r\n",
        "from torchtext import data\r\n",
        "import pandas as pd\r\n",
        "from konlpy.tag import Komoran "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY4Ial7IlSHl"
      },
      "source": [
        "## Change xlsx file to csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knNCvPwlehKd"
      },
      "source": [
        "dataset = pd.read_excel('/content/drive/MyDrive/korean_sementic_dataset.xlsx')\r\n",
        "dataset.to_csv('/content/drive/MyDrive/korean_smentic_dataset_ver_one.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtidaWa7f5up",
        "outputId": "a9ef9000-27b8-4926-98c7-98a68b764086"
      },
      "source": [
        "# for compare to csv file \r\n",
        "print(dataset.head(5))\r\n",
        "\r\n",
        "dataset2 = pd.read_csv('/content/drive/MyDrive/korean_smentic_dataset_ver_one.csv')\r\n",
        "dataset2.drop(dataset2.columns[0], axis = 1, inplace = True) # drop unknown column\r\n",
        "print(dataset2.head(5))\r\n",
        "dataset2.to_csv('/content/drive/MyDrive/korean_smentic_dataset_ver_one.csv')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   Sentence Emotion\n",
            "0  언니 동생으로 부르는게 맞는 일인가요..??      공포\n",
            "1              그냥 내 느낌일뿐겠지?      공포\n",
            "2            아직너무초기라서 그런거죠?      공포\n",
            "3             유치원버스 사고 낫다던데      공포\n",
            "4               근데 원래이런거맞나요      공포\n",
            "                   Sentence Emotion\n",
            "0  언니 동생으로 부르는게 맞는 일인가요..??      공포\n",
            "1              그냥 내 느낌일뿐겠지?      공포\n",
            "2            아직너무초기라서 그런거죠?      공포\n",
            "3             유치원버스 사고 낫다던데      공포\n",
            "4               근데 원래이런거맞나요      공포\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_2BuGlheMGf"
      },
      "source": [
        "## Define data_loader Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK5iA8AaeLhD"
      },
      "source": [
        "komoran = Komoran()\r\n",
        "\r\n",
        "class DataLoader(object):\r\n",
        "  def __init__(self, train_fn, batch_size = 64, valid_ratio = .2, device = -1, max_vocab = 99999, min_freq = 5, use_eos = False, shuffle = True):\r\n",
        "    # train_fn : train dataset path, max_vocab : max vocab size, min_freq : minimum frequency for loaded word\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.label = data.Field(\r\n",
        "        sequential = False,\r\n",
        "        use_vocab = True,\r\n",
        "        unk_token = False\r\n",
        "    )\r\n",
        "    self.text = data.Field(\r\n",
        "        use_vocab = True,\r\n",
        "        batch_first = True,\r\n",
        "        include_lengths = False,\r\n",
        "        tokenize = komoran # use komoran\r\n",
        "    )\r\n",
        "\r\n",
        "    train, valid = data.TabularDataset(\r\n",
        "        path = '/content/drive/MyDrive/korean_smentic_dataset_ver_one.csv',\r\n",
        "        format = 'csv',\r\n",
        "        fields = [\r\n",
        "                  ('text', self.text),\r\n",
        "                  ('label', self.label),\r\n",
        "        ],\r\n",
        "    ).split(split_ratio = (1-valid_ratio))\r\n",
        "\r\n",
        "    self.train_loader, self.test_loader = data.BucketIterator.splits(\r\n",
        "        (train, valid),\r\n",
        "        batch_size = batch_size,\r\n",
        "        device = 'cpu',\r\n",
        "        shuffle = shuffle,\r\n",
        "        sort_key = lambda x: len(x.text),\r\n",
        "        sort_within_batch = True, \r\n",
        "    )\r\n",
        "    \r\n",
        "    self.label.build_vocab(train)\r\n",
        "    self.text.build_vocab(train, max_size = max_vocab, min_freq = min_freq)"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}